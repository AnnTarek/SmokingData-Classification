{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import useful_functions\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import BayesSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data\n",
    "train_df = useful_functions.get_normalized_train()\n",
    "val_df = useful_functions.get_normalized_val()\n",
    "test_df = useful_functions.get_normalized_test()\n",
    "\n",
    "X_train = train_df.drop(columns=['smoking']).to_numpy()\n",
    "y_train = train_df['smoking'].to_numpy()\n",
    "\n",
    "X_val = val_df.drop(columns=['smoking']).to_numpy()\n",
    "y_val = val_df['smoking'].to_numpy()\n",
    "\n",
    "X_test = test_df.drop(columns=['smoking']).to_numpy()\n",
    "y_test = test_df['smoking'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost With Decision Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class MyAdaBoostTree(BaseEstimator):\n",
    "    def __init__(self, num_iterations=10, max_tree_height = 1):\n",
    "        self.num_iterations = num_iterations\n",
    "        self.max_tree_height = max_tree_height\n",
    "\n",
    "    def train(self, X, y):\n",
    "        return self.fit(X,y)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples = X.shape[0]\n",
    "        self.alphas__ = []\n",
    "        self.models__ = []\n",
    "        sample_weights = np.ones((num_samples))/num_samples\n",
    "        for iteration in range(self.num_iterations):\n",
    "            weak_learner = DecisionTreeClassifier(criterion='gini', max_depth=self.max_tree_height)\n",
    "            weak_learner.fit(X, y, sample_weight=sample_weights)\n",
    "\n",
    "            sample_predictions = weak_learner.predict(X)\n",
    "            incorrect = (sample_predictions != y)*1 #Multiply by 1 to convert True/False to 1/0\n",
    "            weighted_error = np.multiply(incorrect, sample_weights).sum()  / sample_weights.sum()\n",
    "            alpha = (0.5) * math.log((1-weighted_error) / weighted_error)\n",
    "            \n",
    "            #Add Model and Alpha to Ensemble\n",
    "            self.alphas__.append(alpha)\n",
    "            self.models__.append(weak_learner)\n",
    "            \n",
    "            #Update Weights\n",
    "            sample_weights = np.multiply(sample_weights, np.exp(2*alpha*incorrect))\n",
    "            sample_weights = sample_weights / sample_weights.sum()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        sum_predictions = np.zeros(X.shape[0])\n",
    "        for idx, model in enumerate(self.models__):\n",
    "            prediction = model.predict(X)\n",
    "            sum_predictions += self.alphas__[idx] * np.where(prediction == 0, -1, prediction)  #np.where used to replace 0s with -1s      \n",
    "        return np.where(sum_predictions >= 0, 1, 0)\n",
    "    \n",
    "\n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        return (prediction == y).sum()/  X.shape[0] \n",
    "\n",
    "    def best_score_(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost With Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAdaBoostLogistic(BaseEstimator):\n",
    "    def __init__(self, num_iterations=10):\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples = X.shape[0]\n",
    "        self.alphas_ = []\n",
    "        self.models_ = []\n",
    "        sample_weights = np.ones((num_samples))/num_samples\n",
    "        for iteration in range(self.num_iterations):\n",
    "            weak_learner = LogisticRegression()\n",
    "            weak_learner.fit(X, y, sample_weight=sample_weights)\n",
    "\n",
    "            sample_predictions = weak_learner.predict(X)\n",
    "            incorrect = (sample_predictions != y)*1 #Multiply by 1 to convert True/False to 1/0\n",
    "            weighted_error = np.multiply(incorrect, sample_weights).sum()  / sample_weights.sum()\n",
    "            alpha = (0.5) * math.log((1-weighted_error) / weighted_error)\n",
    "            \n",
    "            #Add Model and Alpha to Ensemble\n",
    "            self.alphas_.append(alpha)\n",
    "            self.models_.append(weak_learner)\n",
    "            \n",
    "            #Update Weights\n",
    "            sample_weights = np.multiply(sample_weights, np.exp(2*alpha*incorrect))\n",
    "            sample_weights = sample_weights / sample_weights.sum()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        sum_predictions = np.zeros(X.shape[0])\n",
    "        for idx, model in enumerate(self.models_):\n",
    "            prediction = model.predict(X)\n",
    "            sum_predictions += self.alphas_[idx] * np.where(prediction == 0, -1, prediction)        \n",
    "        return np.where(sum_predictions >= 0, 1, 0)\n",
    "    \n",
    "\n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        return (prediction == y).sum()/ X.shape[0]  \n",
    "    \n",
    "\n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        return (prediction == y).sum()/ X.shape[0]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from collections import Counter\n",
    "\n",
    "class MyRandomForest(BaseEstimator):\n",
    "    def __init__(self, num_trees=10, max_height=5, max_features=5):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_height = max_height\n",
    "        self.max_features = max_features\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.trees_ = [] \n",
    "        num_samples = X.shape[0]       \n",
    "        for i in range(self.num_trees):\n",
    "            samples = np.random.choice(num_samples, size=num_samples, replace=True)\n",
    "            sampled_X = X[samples]\n",
    "            sampled_Y = y[samples]\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_height, max_features=self.max_features)\n",
    "            tree.fit(sampled_X, sampled_Y)\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees_])     \n",
    "        mode_predictions =np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=predictions)\n",
    "        return mode_predictions\n",
    "    \n",
    "\n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        return (prediction == y).sum()/  X.shape[0]   \n",
    "    \n",
    "    def train(self, X, y):\n",
    "        return self.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging With Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing Bagging from scratch\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyBagging(BaseEstimator):\n",
    "    def __init__(self, num_trees=10, max_height=5):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_height = max_height    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        num_samples  = X.shape[0]        \n",
    "        for i in range(self.num_trees):\n",
    "            samples = np.random.choice(num_samples, size=num_samples, replace=True)\n",
    "            sampled_X = X[samples]\n",
    "            sampled_Y = y[samples]\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_height)\n",
    "            tree.fit(sampled_X, sampled_Y)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    # calculate the prediction of each tree and return the maximum voted prediction\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        mode_predictions =np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=predictions)\n",
    "        return mode_predictions\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        return (prediction == y).sum()/  X.shape[0]\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        return self.fit(X, y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging using KNN from scratch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class MyBaggingKNN(BaseEstimator):\n",
    "    def __init__(self, num_models=10, k=3):\n",
    "        self.num_models = num_models\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.models = []\n",
    "        num_samples  = X_train.shape[0]        \n",
    "        for i in range(self.num_models):\n",
    "            samples = np.random.choice(num_samples, size=num_samples, replace=True)\n",
    "            sampled_X = X_train[samples]\n",
    "            sampled_Y = y_train[samples]\n",
    "            model = KNeighborsClassifier(n_neighbors=self.k)\n",
    "            model.fit(sampled_X, sampled_Y)\n",
    "            self.models.append(model)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        mode_predictions =np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=predictions)\n",
    "        return mode_predictions\n",
    "    \n",
    "\n",
    "    def score(self, X, y):\n",
    "        prediction = self.predict(X)\n",
    "        return (prediction == y).sum()/  X.shape[0]\n",
    "    \n",
    "\n",
    "    def train(self, X, y):\n",
    "        return self.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search From Scratch (With Threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Grid Search from scratch using threads\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "class MyGridSearch():\n",
    "    def __init__(self, model, params, cv):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.cv = cv\n",
    "        self.best_model = None\n",
    "        self.best_score = 0\n",
    "        self.best_params = None\n",
    "        self.predictions = []\n",
    "\n",
    "    def worker(self,model, X_train, y_train, X_val, y_val):\n",
    "        print(f\"size of X_train: {X_train.shape}\")\n",
    "        print(f\"size of X_val: {X_val.shape}\")\n",
    "        model.train(X_train, y_train)\n",
    "        self.predictions.append((model.score(X_val, y_val), model.get_params()))\n",
    "\n",
    "    def grid_search(self):\n",
    "        parameters_grid = ParameterGrid(self.params)\n",
    "        number_of_models = len(parameters_grid)\n",
    "        print(f\"Number of models: {number_of_models}\")\n",
    "        for i in range(number_of_models):\n",
    "            # set the parameters for the model\n",
    "            self.model.set_params(**parameters_grid[i])\n",
    "            # Create a thread for each model\n",
    "            training_ratio = (self.cv - 1)  / self.cv\n",
    "            X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(X_train, y_train, train_size=training_ratio, random_state=42)\n",
    "            t = Thread(target=self.worker, args=(self.model, X_train_new, y_train_new, X_val_new, y_val_new))\n",
    "            t.start()\n",
    "            t.join()\n",
    "        return max(self.predictions)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 5\n",
      "size of X_train: (98260, 8)\n",
      "size of X_val: (24565, 8)\n",
      "size of X_train: (98260, 8)\n",
      "size of X_val: (24565, 8)\n",
      "size of X_train: (98260, 8)\n",
      "size of X_val: (24565, 8)\n",
      "size of X_train: (98260, 8)\n",
      "size of X_val: (24565, 8)\n",
      "size of X_train: (98260, 8)\n",
      "size of X_val: (24565, 8)\n",
      "(0.7375127213515164, {'max_tree_height': 1, 'num_iterations': 50})\n"
     ]
    }
   ],
   "source": [
    "adaboost = MyAdaBoostTree(num_iterations= 100)\n",
    "clf = MyGridSearch(adaboost, {\"num_iterations\": [10, 20, 30, 40, 50]}, 5)\n",
    "print(clf.grid_search())\n",
    "\n",
    "#randomForest = MyRandomForest(num_trees=50, max_height=12, max_features=3, num_samples=num_samples)\n",
    "#clf = MyGridSearch(randomForest, {\"num_trees\": [10, 20, 30, 40, 50]}, 5)\n",
    "#print(clf.grid_search())\n",
    "\n",
    "#bagging = MyBagging(num_trees=10, max_height=12, max_features=3)\n",
    "#clf = MyGridSearch(bagging, {\"num_trees\": [10, 20, 30, 40, 50]}, 5)\n",
    "#print(clf.grid_search())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Grid Search for Boosting\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m adaboost \u001b[38;5;241m=\u001b[39m MyAdaBoostTree(\u001b[43mnum_samples\u001b[49m, num_features)\n\u001b[1;32m      6\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_iterations\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m500\u001b[39m]}\n\u001b[1;32m      7\u001b[0m cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_samples' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for Boosting\n",
    "adaboost = MyAdaBoostTree(num_samples, num_features)\n",
    "parameters = {'num_iterations': [10, 20, 50, 100, 200, 300, 400, 500]}\n",
    "cv=5\n",
    "clf = MyGridSearch(adaboost, parameters, cv=cv)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(clf.score(X_val, y_val))\n",
    "\n",
    "# Grid Search for Random Forest\n",
    "forest = MyRandomForest(num_trees=50, max_height=12, max_features=3, num_samples=num_samples)\n",
    "parameters = {'num_trees': [10, 20, 50, 100, 200, 300, 400, 500]}\n",
    "clf = GridSearchCV(forest, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(clf.score(X_val, y_val))\n",
    "\n",
    "# Grid Search for Bagging\n",
    "#bagging = MyBagging(num_trees=10, max_height=12, max_features=3)\n",
    "#parameters = {'num_trees': [10, 20, 50, 100, 200, 300, 400, 500]}\n",
    "#clf = GridSearchCV(bagging, parameters, cv=5)\n",
    "#clf.fit(X_train, y_train)\n",
    "#print(clf.best_params_)\n",
    "#print(clf.best_score_)\n",
    "parameters = {'num_iterations': [10, 20, 30]}\n",
    "clf = GridSearchCV(adaboost, parameters, cv=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(clf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search (Sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "{'max_tree_height': 3, 'num_iterations': 300}\n",
      "0.7467290889979337\n",
      "0.750031395202813\n",
      "Mean cross-validated training accuracy score: 0.7467290889979337\n",
      "\n",
      "Best Hyperparameter Combination: {'max_tree_height': 3, 'num_iterations': 300}\n",
      "\n",
      "Validation Score: 0.750031395202813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for Boosting\n",
    "adaboost = MyAdaBoostTree()\n",
    "hyperparameters = {'num_iterations': [10, 20, 50, 100, 200, 300], 'max_tree_height': [1,2,3]}\n",
    "clf = GridSearchCV(adaboost, hyperparameters, cv=2, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(clf.score(X_val, y_val))\n",
    "\n",
    "print(f\"Mean cross-validated training accuracy score: {clf.best_score_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {clf.best_params_}\\n\")\n",
    "print(f\"Validation Score: {clf.score(X_val, y_val)}\\n\")\n",
    "\n",
    "val_boost_tree_grid = clf.score(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] END ..................................num_iterations=10; total time=   0.4s\n",
      "[CV] END ..................................num_iterations=10; total time=   0.3s\n",
      "[CV] END ..................................num_iterations=20; total time=   0.9s\n",
      "[CV] END ..................................num_iterations=20; total time=   1.6s\n",
      "[CV] END ..................................num_iterations=50; total time=   2.3s\n",
      "[CV] END ..................................num_iterations=50; total time=   3.1s\n",
      "[CV] END .................................num_iterations=100; total time=   4.2s\n",
      "[CV] END .................................num_iterations=100; total time=   3.2s\n",
      "[CV] END .................................num_iterations=200; total time=   7.3s\n",
      "[CV] END .................................num_iterations=200; total time=   7.0s\n",
      "[CV] END .................................num_iterations=300; total time=  10.1s\n",
      "[CV] END .................................num_iterations=300; total time=   9.7s\n",
      "Mean cross-validated training accuracy score: 0.7280928094608429\n",
      "\n",
      "Best Hyperparameter Combination: {'num_iterations': 20}\n",
      "\n",
      "Validation Score: 0.7280547532337059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for Boosting\n",
    "adaboost = MyAdaBoostLogistic()\n",
    "hyperparameters = {'num_iterations': [10, 20, 50, 100, 200, 300]}\n",
    "clf = GridSearchCV(adaboost, hyperparameters, cv=2, verbose=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {clf.best_score_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {clf.best_params_}\\n\")\n",
    "print(f\"Validation Score: {clf.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_boost_logistic_grid = clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "Mean cross-validated training accuracy score: 0.7485365394169421\n",
      "\n",
      "Best Hyperparameter Combination: {'max_height': 10, 'num_trees': 30}\n",
      "\n",
      "Validation Score: 0.7497174431746829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for Boosting\n",
    "forest = MyRandomForest()\n",
    "hyperparameters = {'num_trees': [10, 20, 30, 40, 50], 'max_height':[3, 5, 10]}\n",
    "clf = GridSearchCV(forest, hyperparameters, cv=2, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {clf.best_score_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {clf.best_params_}\\n\")\n",
    "print(f\"Validation Score: {clf.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_forest_grid = clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "Mean cross-validated training accuracy score: 0.7473397230846132\n",
      "\n",
      "Best Hyperparameter Combination: {'max_height': 10, 'num_trees': 20}\n",
      "\n",
      "Validation Score: 0.7510360416928293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for Boosting\n",
    "bagging = MyBagging()\n",
    "hyperparameters = {'num_trees': [10, 20], 'max_height':[3, 5, 10]}\n",
    "clf = GridSearchCV(bagging, hyperparameters, cv=2, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {clf.best_score_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {clf.best_params_}\\n\")\n",
    "print(f\"Validation Score: {clf.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_bagging_grid = clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] END ..................................k=3, num_models=3; total time=  23.5s\n",
      "[CV] END ..................................k=3, num_models=3; total time=  23.6s\n",
      "[CV] END ..................................k=3, num_models=5; total time=  30.9s\n",
      "[CV] END ..................................k=3, num_models=5; total time=  28.6s\n",
      "[CV] END ..................................k=5, num_models=3; total time=  18.6s\n",
      "[CV] END ..................................k=5, num_models=3; total time=  20.2s\n",
      "[CV] END ..................................k=5, num_models=5; total time=  34.0s\n",
      "[CV] END ..................................k=5, num_models=5; total time=  25.7s\n",
      "{'k': 5, 'num_models': 5}\n",
      "0.7055974036626869\n",
      "0.7110385533090544\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for BaggingKNN\n",
    "bagging = MyBaggingKNN()\n",
    "hyperparameters = {'num_models': [3, 5], 'k':[3, 5]}\n",
    "clf = GridSearchCV(bagging, hyperparameters, cv=2, verbose=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {clf.best_score_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {clf.best_params_}\\n\")\n",
    "print(f\"Validation Score: {clf.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_bagging_knn_grid = clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ...............max_tree_height=1, num_iterations=40; total time=   2.5s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=40; total time=   4.1s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=40; total time=   4.0s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=40; total time=   3.7s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=40; total time=   4.6s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   2.8s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   2.2s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   3.6s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   3.1s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   3.2s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   7.2s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   6.9s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   5.8s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   6.0s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   4.8s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=20; total time=   1.3s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=20; total time=   1.4s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=20; total time=   1.4s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=20; total time=   1.0s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=20; total time=   1.6s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   2.5s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   2.0s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   2.1s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   1.9s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=30; total time=   1.5s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=50; total time=   3.6s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=50; total time=   2.7s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=50; total time=   3.5s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=50; total time=   4.1s\n",
      "[CV] END ...............max_tree_height=1, num_iterations=50; total time=   3.5s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=30; total time=   3.8s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=30; total time=   3.3s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=30; total time=   3.8s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=30; total time=   4.2s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=30; total time=   3.8s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   7.0s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   6.4s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   6.2s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   5.4s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=50; total time=   6.7s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=40; total time=   5.4s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=40; total time=   5.5s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=40; total time=   5.1s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=40; total time=   5.3s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=40; total time=   5.6s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=20; total time=   2.7s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=20; total time=   2.9s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=20; total time=   2.7s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=20; total time=   2.4s\n",
      "[CV] END ...............max_tree_height=2, num_iterations=20; total time=   2.9s\n",
      "Mean cross-validated training accuracy score: 0.7432281701607979\n",
      "\n",
      "Best Estimator: MyAdaBoostTree(max_tree_height=2, num_iterations=50)\n",
      "\n",
      "Best Hyperparameter Combination: {'max_tree_height': 2, 'num_iterations': 50}\n",
      "\n",
      "Validation Score: 0.7475825693833982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning using Random Search for AdaboostTree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "hyperparameters = {'num_iterations': [10, 15, 20, 25, 30,  35, 40, 45, 50],\n",
    "                   'max_tree_height': [1,2,3,4,5]}\n",
    "adaboost = MyAdaBoostTree()\n",
    "rs = RandomizedSearchCV(adaboost, hyperparameters,cv=2, verbose=2, random_state=42)\n",
    "rs.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rs.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rs.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rs.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rs.score(X_val, y_val)}\\n\")\n",
    "\n",
    "val_boost_tree_rand = rs.score(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ..................................num_iterations=25; total time=   1.3s\n",
      "[CV] END ..................................num_iterations=25; total time=   1.4s\n",
      "[CV] END ..................................num_iterations=25; total time=   1.7s\n",
      "[CV] END ..................................num_iterations=25; total time=   1.3s\n",
      "[CV] END ..................................num_iterations=25; total time=   1.1s\n",
      "[CV] END ...................................num_iterations=3; total time=   0.1s\n",
      "[CV] END ...................................num_iterations=3; total time=   0.2s\n",
      "[CV] END ...................................num_iterations=3; total time=   0.4s\n",
      "[CV] END ...................................num_iterations=3; total time=   0.4s\n",
      "[CV] END ...................................num_iterations=3; total time=   0.2s\n",
      "[CV] END ..................................num_iterations=45; total time=   3.3s\n",
      "[CV] END ..................................num_iterations=45; total time=   2.7s\n",
      "[CV] END ..................................num_iterations=45; total time=   2.1s\n",
      "[CV] END ..................................num_iterations=45; total time=   2.3s\n",
      "[CV] END ..................................num_iterations=45; total time=   2.0s\n",
      "[CV] END ..................................num_iterations=50; total time=   2.0s\n",
      "[CV] END ..................................num_iterations=50; total time=   1.9s\n",
      "[CV] END ..................................num_iterations=50; total time=   1.9s\n",
      "[CV] END ..................................num_iterations=50; total time=   2.0s\n",
      "[CV] END ..................................num_iterations=50; total time=   2.3s\n",
      "[CV] END ..................................num_iterations=10; total time=   0.3s\n",
      "[CV] END ..................................num_iterations=10; total time=   0.5s\n",
      "[CV] END ..................................num_iterations=10; total time=   0.6s\n",
      "[CV] END ..................................num_iterations=10; total time=   0.5s\n",
      "[CV] END ..................................num_iterations=10; total time=   0.5s\n",
      "[CV] END ...................................num_iterations=5; total time=   0.5s\n",
      "[CV] END ...................................num_iterations=5; total time=   0.3s\n",
      "[CV] END ...................................num_iterations=5; total time=   0.2s\n",
      "[CV] END ...................................num_iterations=5; total time=   0.3s\n",
      "[CV] END ...................................num_iterations=5; total time=   0.4s\n",
      "[CV] END ..................................num_iterations=40; total time=   2.2s\n",
      "[CV] END ..................................num_iterations=40; total time=   3.4s\n",
      "[CV] END ..................................num_iterations=40; total time=   2.3s\n",
      "[CV] END ..................................num_iterations=40; total time=   2.3s\n",
      "[CV] END ..................................num_iterations=40; total time=   3.4s\n",
      "[CV] END ..................................num_iterations=20; total time=   1.1s\n",
      "[CV] END ..................................num_iterations=20; total time=   0.9s\n",
      "[CV] END ..................................num_iterations=20; total time=   0.8s\n",
      "[CV] END ..................................num_iterations=20; total time=   1.1s\n",
      "[CV] END ..................................num_iterations=20; total time=   0.8s\n",
      "[CV] END ..................................num_iterations=35; total time=   1.5s\n",
      "[CV] END ..................................num_iterations=35; total time=   2.3s\n",
      "[CV] END ..................................num_iterations=35; total time=   1.6s\n",
      "[CV] END ..................................num_iterations=35; total time=   1.8s\n",
      "[CV] END ..................................num_iterations=35; total time=   1.7s\n",
      "[CV] END ..................................num_iterations=15; total time=   1.6s\n",
      "[CV] END ..................................num_iterations=15; total time=   1.4s\n",
      "[CV] END ..................................num_iterations=15; total time=   1.1s\n",
      "[CV] END ..................................num_iterations=15; total time=   1.8s\n",
      "[CV] END ..................................num_iterations=15; total time=   1.6s\n",
      "Mean cross-validated training accuracy score: 0.7225239161408508\n",
      "\n",
      "Best Estimator: MyAdaBoostLogistic(num_iterations=15)\n",
      "\n",
      "Best Hyperparameter Combination: {'num_iterations': 15}\n",
      "\n",
      "Validation Score: 0.7270501067436895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning using Random Search for AdaboostTree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "hyperparameters = {'num_iterations': [3, 5, 10, 15, 20, 25, 30, 35, 40,45, 50]}\n",
    "adaboost = MyAdaBoostLogistic()\n",
    "rs = RandomizedSearchCV(adaboost, hyperparameters, cv=2, verbose=2, random_state=42)\n",
    "rs.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rs.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rs.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rs.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rs.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_boost_logistic_rand = rs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END ........max_features=3, max_height=3, num_trees=200; total time=  20.0s\n",
      "[CV] END ........max_features=3, max_height=3, num_trees=200; total time=  14.6s\n",
      "[CV] END ........max_features=2, max_height=3, num_trees=200; total time=  12.4s\n",
      "[CV] END ........max_features=2, max_height=3, num_trees=200; total time=  15.2s\n",
      "[CV] END .........max_features=4, max_height=3, num_trees=20; total time=   3.0s\n",
      "[CV] END .........max_features=4, max_height=3, num_trees=20; total time=   3.1s\n",
      "[CV] END .......max_features=4, max_height=10, num_trees=200; total time=  46.2s\n",
      "[CV] END .......max_features=4, max_height=10, num_trees=200; total time=  47.2s\n",
      "[CV] END .........max_features=1, max_height=3, num_trees=10; total time=   1.0s\n",
      "[CV] END .........max_features=1, max_height=3, num_trees=10; total time=   1.4s\n",
      "[CV] END .........max_features=2, max_height=5, num_trees=50; total time=   4.5s\n",
      "[CV] END .........max_features=2, max_height=5, num_trees=50; total time=   4.1s\n",
      "[CV] END ........max_features=3, max_height=3, num_trees=100; total time=   8.2s\n",
      "[CV] END ........max_features=3, max_height=3, num_trees=100; total time=   7.7s\n",
      "[CV] END ........max_features=4, max_height=5, num_trees=500; total time=  55.8s\n",
      "[CV] END ........max_features=4, max_height=5, num_trees=500; total time= 1.1min\n",
      "[CV] END ........max_features=1, max_height=5, num_trees=200; total time=  14.9s\n",
      "[CV] END ........max_features=1, max_height=5, num_trees=200; total time=  15.4s\n",
      "[CV] END .........max_features=3, max_height=5, num_trees=50; total time=   6.4s\n",
      "[CV] END .........max_features=3, max_height=5, num_trees=50; total time=   6.0s\n",
      "Mean cross-validated training accuracy score: 0.7492285831269406\n",
      "\n",
      "Best Estimator: MyRandomForest(max_features=4, max_height=10, num_trees=200)\n",
      "\n",
      "Best Hyperparameter Combination: {'num_trees': 200, 'max_height': 10, 'max_features': 4}\n",
      "\n",
      "Validation Score: 0.7508476704759512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning using Random Search for Random Forest\n",
    "hyperparameters = {'num_trees': [10, 20, 50, 100, 200, 500],\n",
    "                    'max_height':[3, 5, 10], \n",
    "                    'max_features': [1,2,3,4,5]}\n",
    "forest = MyRandomForest()\n",
    "rs = RandomizedSearchCV(forest, hyperparameters, cv=2, verbose=2, random_state=42)\n",
    "rs.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rs.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rs.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rs.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rs.score(X_val, y_val)}\\n\")\n",
    "\n",
    "val_forest_rand = rs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END .........................max_height=3, num_trees=10; total time=   1.5s\n",
      "[CV] END .........................max_height=3, num_trees=10; total time=   2.3s\n",
      "[CV] END .........................max_height=3, num_trees=20; total time=   3.2s\n",
      "[CV] END .........................max_height=3, num_trees=20; total time=   2.5s\n",
      "[CV] END .........................max_height=5, num_trees=50; total time=   9.1s\n",
      "[CV] END .........................max_height=5, num_trees=50; total time=  10.6s\n",
      "[CV] END ........................max_height=3, num_trees=500; total time= 1.0min\n",
      "[CV] END ........................max_height=3, num_trees=500; total time= 1.2min\n",
      "[CV] END ........................max_height=3, num_trees=100; total time=  13.6s\n",
      "[CV] END ........................max_height=3, num_trees=100; total time=  14.6s\n",
      "[CV] END ........................max_height=10, num_trees=20; total time=   8.9s\n",
      "[CV] END ........................max_height=10, num_trees=20; total time=   7.8s\n",
      "[CV] END .......................max_height=10, num_trees=200; total time= 1.1min\n",
      "[CV] END .......................max_height=10, num_trees=200; total time= 1.1min\n",
      "[CV] END .......................max_height=10, num_trees=100; total time=  32.7s\n",
      "[CV] END .......................max_height=10, num_trees=100; total time=  32.6s\n",
      "[CV] END ........................max_height=5, num_trees=500; total time= 1.4min\n",
      "[CV] END ........................max_height=5, num_trees=500; total time= 1.3min\n",
      "[CV] END .........................max_height=3, num_trees=50; total time=   5.2s\n",
      "[CV] END .........................max_height=3, num_trees=50; total time=   4.6s\n",
      "Mean cross-validated training accuracy score: 0.7484388423539049\n",
      "\n",
      "Best Estimator: MyBagging(max_height=10, num_trees=200)\n",
      "\n",
      "Best Hyperparameter Combination: {'num_trees': 200, 'max_height': 10}\n",
      "\n",
      "Validation Score: 0.7505337184478211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning using Random Search for Random Forest\n",
    "hyperparameters = {'num_trees': [10, 20, 50, 100, 200, 500],\n",
    "                    'max_height':[3, 5, 10]}\n",
    "bagging = MyBagging()\n",
    "rs = RandomizedSearchCV(bagging, hyperparameters, cv=2, verbose=2, random_state=42)\n",
    "rs.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rs.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rs.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rs.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rs.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_bagging_rand = rs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bayesian Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m adaboost \u001b[38;5;241m=\u001b[39m MyAdaBoostTree()\n\u001b[1;32m      5\u001b[0m rf \u001b[38;5;241m=\u001b[39m BayesSearchCV(adaboost, hyperparameters, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean cross-validated training accuracy score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Estimator: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 512\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/searchcv.py:400\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# get parameter values to evaluate\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[1;32m    403\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:395\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    393\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_points):\n\u001b[0;32m--> 395\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    398\u001b[0m     ti_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_func \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(opt\u001b[38;5;241m.\u001b[39myi) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:367\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query point or multiple points at which objective should be evaluated.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03mn_points : int or None, default: None\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m \n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m supported_strategies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_min\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_max\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(n_points, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m n_points \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:434\u001b[0m, in \u001b[0;36mOptimizer._ask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_initial_points \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_estimator_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# this will not make a copy of `self.rng` and hence keep advancing\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# our random state.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;66;03m# The samples are evaluated starting form initial_samples[0]\u001b[39;00m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples[\n\u001b[1;32m    438\u001b[0m             \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_initial_points]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/space/space.py:900\u001b[0m, in \u001b[0;36mSpace.rvs\u001b[0;34m(self, n_samples, random_state)\u001b[0m\n\u001b[1;32m    897\u001b[0m columns \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions:\n\u001b[0;32m--> 900\u001b[0m     columns\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# Transpose\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _transpose_list_array(columns)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/space/space.py:698\u001b[0m, in \u001b[0;36mCategorical.rvs\u001b[0;34m(self, n_samples, random_state)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse_transform([(choices)])\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m choices]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/space/space.py:685\u001b[0m, in \u001b[0;36mCategorical.inverse_transform\u001b[0;34m(self, Xt)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;124;03m   original space.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# The concatenation of all transformed dimensions makes Xt to be\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# of type float, hence the required cast back to int.\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m inv_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inv_transform, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    687\u001b[0m     inv_transform \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(inv_transform)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/space/space.py:168\u001b[0m, in \u001b[0;36mDimension.inverse_transform\u001b[0;34m(self, Xt)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, Xt):\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m       original space.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/space/transformers.py:309\u001b[0m, in \u001b[0;36mPipeline.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transformer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 309\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/skopt/space/transformers.py:275\u001b[0m, in \u001b[0;36mNormalize.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    273\u001b[0m X_orig \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_int:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mround(X_orig)\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_orig\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "hyperparameters = {'num_iterations': [10, 15, 20, 25, 30,  35, 40, 45, 50],\n",
    "                   'max_tree_height': [1,2,3,4,5]}\n",
    "adaboost = MyAdaBoostTree()\n",
    "rf = BayesSearchCV(adaboost, hyperparameters, cv=2, verbose=2, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rf.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rf.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rf.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rf.score(X_val, y_val)}\\n\")\n",
    "\n",
    "val_boost_tree_bayes = rf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'num_iterations': [3, 5, 10, 15, 20, 25, 30, 35, 40,45, 50]}\n",
    "adaboost = MyAdaBoostLogistic()\n",
    "rs = BayesSearchCV(adaboost, hyperparameters, cv=2, verbose=2, random_state=42)\n",
    "rs.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rs.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rs.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rs.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rs.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_boost_logistic_bayes = rs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning using Bayesian Search for Random Forest\n",
    "hyperparameters = {'num_trees': [10, 20, 50, 100, 200, 500],\n",
    "                    'max_height':[3, 5, 10], \n",
    "                    'max_features': [1,2,3,4,5]}\n",
    "forest = MyRandomForest()\n",
    "rs = BayesSearchCV(forest, hyperparameters, cv=2, verbose=2, random_state=42)\n",
    "rs.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rs.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rs.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rs.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rs.score(X_val, y_val)}\\n\")\n",
    "\n",
    "val_forest_bayes = rs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning using Bayesian Search for Random Forest\n",
    "hyperparameters = {'num_trees': [10, 20, 50, 100, 200, 500],\n",
    "                    'max_height':[3, 5, 10]}\n",
    "bagging = MyBagging()\n",
    "rs = BayesSearchCV(bagging, hyperparameters, cv=2, verbose=2, random_state=42)\n",
    "rs.fit(X_train, y_train)\n",
    "print(f\"Mean cross-validated training accuracy score: {rs.best_score_}\\n\")\n",
    "print(f\"Best Estimator: {rs.best_estimator_}\\n\")\n",
    "print(f\"Best Hyperparameter Combination: {rs.best_params_}\\n\")\n",
    "print(f\"Validation Score: {rs.score(X_val, y_val)}\\n\")\n",
    "\n",
    "\n",
    "val_bagging_bayes = rs.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparing Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "highest_boosting_tree = max(val_boost_tree_grid, val_boost_tree_rand)\n",
    "highest_boosting_logistic = max(val_boost_logistic_grid, val_boost_logistic_rand)\n",
    "highest_forest = max(val_forest_grid, val_forest_rand)\n",
    "highest_bagging = max(val_bagging_grid, val_bagging_rand)\n",
    "highest_bagging_knn = val_bagging_knn_grid\n",
    "\n",
    "\n",
    "model_names =  [\"Boosting (Trees)\", \"Boosting (Logistic)\", \"Random Forest\", \"Baggin (Trees)\", \"Baggin (KNN)\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(model_names, [highest_boosting_tree, highest_boosting_logistic, highest_forest, highest_bagging, highest_bagging_knn])\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Max Validatio Accuracy')\n",
    "plt.title('Bar Chart with Features and Absolute Logistic Coefficients')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.ylim(0.7, plt.ylim()[1]) \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy  0.7523546402109758\n"
     ]
    }
   ],
   "source": [
    "#Using Random Forest (Best Model)\n",
    "\n",
    "forest = MyRandomForest(num_trees= 200, max_height= 10, max_features= 4)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "final_test_accuracy = forest.score(X_test, y_test)\n",
    "\n",
    "print(\"Final Test Accuracy \", final_test_accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
